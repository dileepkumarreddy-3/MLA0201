# -*- coding: utf-8 -*-
"""ID3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ayVL7IU4q-XWPC7d_XAlYjSfi1ss_8YF
"""



import pandas as pd
import math
# Step 1: Create Dataset (Play Tennis)
data = {
    'Outlook': ['Sunny','Sunny','Overcast','Rain','Rain','Rain','Overcast',
                'Sunny','Sunny','Rain','Sunny','Overcast','Overcast','Rain'],
    'Temperature': ['Hot','Hot','Hot','Mild','Cool','Cool','Mild',
                    'Cool','Mild','Mild','Mild','Hot','Hot','Mild'],
    'Humidity': ['High','High','High','High','Normal','Normal','High',
                 'Normal','Normal','Normal','High','Normal','High','Normal'],
    'Wind': ['Weak','Strong','Weak','Weak','Weak','Strong','Strong',
             'Weak','Weak','Weak','Strong','Strong','Weak','Strong'],
    'PlayTennis': ['No','No','Yes','Yes','Yes','No','Yes',
                    'No','Yes','Yes','No','Yes','Yes','No']
}
df = pd.DataFrame(data)
print("Dataset:\n")
print(df)
# Step 2: Entropy Function
def entropy(target_col):
    values = target_col.value_counts()
    entropy_val = 0
    for count in values:
        prob = count / sum(values)
        entropy_val -= prob * math.log2(prob)
    return entropy_val
# Step 3: Information Gain
def information_gain(data, feature, target):
    total_entropy = entropy(data[target])
    values = data[feature].unique()
    weighted_entropy = 0
    for val in values:
        subset = data[data[feature] == val]
        weighted_entropy += (len(subset) / len(data)) * entropy(subset[target])
    return total_entropy - weighted_entropy
# Step 4: ID3 Algorithm
def id3(data, features, target):
    # If all target values are same, return that value
    if len(data[target].unique()) == 1:
        return data[target].iloc[0]
    # If no features left, return majority class
    if len(features) == 0:
        return data[target].mode()[0]
    # Select feature with max information gain
    gains = {feature: information_gain(data, feature, target) for feature in features}
    best_feature = max(gains, key=gains.get)
    tree = {best_feature: {}}
    for value in data[best_feature].unique():
        subset = data[data[best_feature] == value]
        remaining_features = features.copy()
        remaining_features.remove(best_feature)
        tree[best_feature][value] = id3(subset, remaining_features, target)
    return tree
# Step 5: Build Decision Tree
features = list(df.columns[:-1])
target = 'PlayTennis'
decision_tree = id3(df, features, target)
print("\nDecision Tree:\n")
print(decision_tree)
# Step 6: Classify New Sample
def classify(sample, tree):
    for feature in tree:
        value = sample[feature]
        subtree = tree[feature].get(value)
        if isinstance(subtree, dict):
            return classify(sample, subtree)
        else:
            return subtree
# New sample
new_sample = {
    'Outlook': 'Sunny',
    'Temperature': 'Cool',
    'Humidity': 'High',
    'Wind': 'Strong'
}
prediction = classify(new_sample, decision_tree)
print("\nNew Sample:", new_sample)
print("Prediction:", prediction)